{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "083c7af8",
   "metadata": {},
   "source": [
    "# Association Analysis\n",
    "\n",
    "\n",
    "## Introduction:\n",
    "Association analysis seeks to discover patterns or rules in a dataset that are somehow \"interesting.\"  The results tell us something we didn't know or expect from our dataset.  This [paper](https://rakesh.agrawal-family.com/papers/sigmod93assoc.pdf) is considered one of the seminal works in this field and is worth a read.  Given a dataset comprised of transactions, the basic idea is to find rules that will predict the occurrence of items based on the occurrences of other items in a transaction.  \n",
    "\n",
    "Association analysis is an unsupervised learning approach, thus requires no *a priori* information like labeled data.  It finds utility in both data exploration and data analytics and yields results that are easily interpreted. \n",
    "\n",
    "One specific application is the analysis of market basket data, which might yield important product couplings that can be used to influence consumer buying habits.  For example, we might find that consumers that buy cough syrup also buy fruit juice.  Thus placing orange juice in the same aisle as cough syrup at a grocery store might increase juice sales.   The idea is summed up well by Andrew Pole, a statistician from Target, who said, “If you’re rushing through the store, looking for baby bottles, and you pass orange juice, you’ll grab a carton. Oh, and there’s that new DVD I want. Soon, you’ll be buying cereal and paper towels from us, and keep coming back.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c4800",
   "metadata": {},
   "source": [
    "## 1. A Little about Set Theory \n",
    "\n",
    "\"A pack of wolves, a bunch of grapes, or a flock of pigeons are all examples of sets of things. The mathematical concept of a set can be used as the foundation of all known mathematics.\"  Paul R. Halmos\n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "* If $S$ is a set and $s$ is an element of $S$, then we write $S \\in S$.\n",
    "* If it so happens that $s$ is not an element of $S$, then we write $S \\notin S$.\n",
    "* If $S$ is the set whose elements are $s$, $t$, and $u$, then we write $S = \\{s, t, u \\}$.\n",
    "* The left and right braces visually indicate the \"bounds\" of the set, while what is written within the bounds indicates the elements of the set.\n",
    "\n",
    "Example: If $S = \\{1,2,3\\}$, then $2 \\in S$, but $4 \\notin S$\n",
    "\n",
    "\n",
    "* Sets are determined by their elements.\n",
    "* The order in which the elements of a given set are listed does not matter.\n",
    "\n",
    "Example: $\\{1, 2, 3\\}$ and $\\{3, 1, 2\\}$ are the same set.\n",
    "\n",
    "* It also does not matter whether some elements of a given set are listed more than once.\n",
    "\n",
    "Example: $\\{1, 2, 2, 2, 3, 3\\}$ is still the set $\\{1, 2, 3\\}$.\n",
    "\n",
    "#### Sets\n",
    "* The set of all even integers\n",
    "* The set of all odd prime numbers\n",
    "* The set of all cities with populations more than one million people\n",
    "* $\\{x:x > 0\\}$ is read aloud, \"the set of all $x$ such that $x$ is greater than 0.\n",
    "* $\\{x \\in \\mathbb{R} : x^2 = 1\\}$\n",
    "\n",
    "* A set $A$ is said to be part of a set $S$ when every element of $A$ is also an element of $S$.  We say that $A$ is a *subset* of $S$. \n",
    "\n",
    "$$ \n",
    "\\text{ $A \\subseteq S$ if and only if, for all $x$, if  $x \\in A$, then $x \\in S$} \n",
    "$$\n",
    "\n",
    "Example:\n",
    "\n",
    "$A = \\{1, 3, 5 \\}, B = \\{1,2, 3, 4, 5 \\}$ \n",
    "\n",
    "$A$ is a subset of $B, A \\subseteq B$ because every element in $A$ is also in $B$.\n",
    "\n",
    "* For two sets $A$ and $B$, the *union* of $A$ and $B$ is the set consisting of the elements that belong to either $A$ and $B$.  Thus,\n",
    "\n",
    "$$\n",
    "A \\cup B = \\{x : x \\in A \\text{ or } x \\in B \\}.\n",
    "$$\n",
    "\n",
    "This is read aloud as \"the set of all $x$ such that $x$ is an element of the set $A$ or $x$ is an element of the set $B$.\n",
    "\n",
    "* For two sets $A$ and $B$, the *intersection* of $A$ and $B$ is the set consisting of the elements of both $A$ and $B$.  Thus,\n",
    "\n",
    "$$\n",
    "A \\cap B = \\{x : x \\in A \\text{ and } x \\in B \\}.\n",
    "$$\n",
    "\n",
    "This is read aloud as \"the set of all $x$ such that $x$ is an element of the set $A$ and $x$ is an element of the set $B$.\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "$A = \\{1, 2, 3 \\}, B = \\{2, 3, 4 \\}$\n",
    "\n",
    "$ A \\cup B = \\{1, 2, 3, 4 \\}$.\n",
    "\n",
    "$ A \\cap B = \\{2, 3\\}$.\n",
    "\n",
    "* The *cardinality* of a set is a measure of the number of elements of the set.\n",
    "* The cardinality of a set is also called its *size*.\n",
    "* The cardinality of a set $A$ is usually denoted $|A|$.\n",
    "\n",
    "Example: \n",
    "\n",
    "$ \\text{The set $A = \\{a, b, c \\}$ contains 3 elements, and therefore has a cardinality or size of 3, or $|A| = 3$}$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeef222",
   "metadata": {},
   "source": [
    "## 2. A Little about Implication\n",
    "* *Implication* is a logical connective (or a binary operator) that can be symbolized by a forward arrow $\\implies$.\n",
    "* It is used to form statements of the form $p \\implies q$ (termed a *conditional statement*), which is read as \"$\\text{if $p$ then $q$}$.\"\n",
    "* $p$ is termed the *antecedent* of the conditional, and $q$ is termed the *consequent* of the conditional.\n",
    "* It does not specify a causal relationship between $p$ and $q$.  It is merely to be understood to mean \"if $p$ is true, then $q$ is also true\"\n",
    "* It makes no claim that $p$ causes $q$.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f5a36",
   "metadata": {},
   "source": [
    "## 3. Formulating the Association Analysis Problem \n",
    "\n",
    "* A database of transaction can be represented as a *market basket* or a database of sales transactions.  Each row is a unique sales transaction comprised of items that were purchased. \n",
    "* Let $I = \\{i_1, i_2, \\dots, i_d\\}$ be the set of all *items* in a market basket.\n",
    "* Let $T = \\{t_1, t_2, \\dots, t_N\\}$ be a set of transactions called *database*, where each transaction $t$ is a set of items such that $t \\subseteq I$.\n",
    "* Each transaction in $T$ is associated with a unique identifier called a *transaction identifier (TID)*\n",
    "\n",
    "Example:\n",
    " \n",
    "\n",
    "From this table of market basket transactions,\n",
    "\n",
    "| TID    | Items |\n",
    "| -------| :-----------|\n",
    "| 1      | Bread, Milk|\n",
    "| 2      | Bread, Diapers, Beer, Eggs|\n",
    "| 3      | Milk, Diapers, Beer, Cola|\n",
    "| 4      | Bread, Milk, Diapers, Beer|\n",
    "| 5      | Bread, Milk, Diapers,Cola|\n",
    "\n",
    "we see that \n",
    "* $I = \\{\\text{Bread, Milk, Diapers, Beer, Eggs, Cola}\\},$ \n",
    "* $t_4 = \\{ \\text{Bread, Milk, Diapers, Beer} \\}, \\text{ and }$ \n",
    "* $|T| = 5.$\n",
    "\n",
    "### Itemsets\n",
    "\n",
    "* Let $X$ be a set of items where $X \\subseteq I$.  $X$ is an *itemset*.\n",
    "* A $k$-itemset is an itemset that contains $k$ items.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* An itemset: $X = \\{\\text{Milk, Bread, Diapers}\\}$\n",
    "* A 2-itemset: $X = \\{\\text{Milk, Diapers}\\}$\n",
    "* A 4-itemset: $X = \\{\\text{Beer, Cola, Milk, Eggs}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b3a17",
   "metadata": {},
   "source": [
    "## 4. Transforming Market Basket Data\n",
    "\n",
    "### Problem\n",
    "You need to transform a dataset comprised of transaction data into an array suitable for typical machine learning APIs.\n",
    "\n",
    "### Solution: \n",
    "Use mlxtend's `TransactionEncoder` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4e5794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Load libraries\n",
    "import pandas as pd\n",
    "#from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Create marketbasket, each row is a transaction\n",
    "\n",
    "basket =  [['Bread', 'Milk'],\n",
    "            ['Bread', 'Diapers', 'Beer', 'Eggs'], \n",
    "            ['Milk', 'Diapers', 'Beer', 'Cola'],\n",
    "            ['Bread', 'Milk', 'Diapers', 'Beer'],\n",
    "            ['Bread', 'Milk', 'Diapers','Cola']]\n",
    "\n",
    "type(basket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a274f",
   "metadata": {},
   "source": [
    "Note that `TransactionEncoder` encodes transaction data in the form of a **Python list of lists** and returns a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7845bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder\n",
    "te = TransactionEncoder()\n",
    "\n",
    "# Transform input data into a one-hot encoded NumPy boolean array\n",
    "te_array = te.fit(basket).transform(basket)\n",
    "te_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc587f44",
   "metadata": {},
   "source": [
    "The NumPy array is boolean for the sake of memory efficiency when working with large datasets. If a classic integer representation is desired instead, we can just convert the array to the appropriate type: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cbfd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "te_array.astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc049f0",
   "metadata": {},
   "source": [
    "After encoding, the unique column names that correspond to the data array can be accessed via the `columns_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "te.columns_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc4fc7",
   "metadata": {},
   "source": [
    "For convenience we convert the encoded array to a pandas `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df68fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basket_df = pd.DataFrame(te_array, columns=te.columns_)\n",
    "basket_df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3d1f4b",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "### mlxtend\n",
    "For association analysis, we'll explore the capabilities of [mlxtend](http://rasbt.github.io/mlxtend/) or \"machine learning extensions.\"  mlxtend states that it is \"a Python library of useful tools for the day-to-day data science tasks.  Incorporated within are modules that support frequent itemset generation, rule generation, employing a number of different metrics to compare rule sets and evaluate their interestingness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb3ff1b",
   "metadata": {},
   "source": [
    "## 5. Support, Support Count\n",
    "\n",
    "* Support count $\\sigma$ is the frequency of occurrence of an itemset in the database.\n",
    "* Support $s$ is the fraction of transactions that contain an itemset in the database,\n",
    "\n",
    "$$\n",
    "s(X) = \\dfrac{\\sigma(X)}{N}.\n",
    "$$.\n",
    "\n",
    "* A *frequent itemset* is an itemset whose support is greater than a user-specified threshold we'll call $minsup$, short for minimum support.\n",
    "* $\\text{If $\\sigma(X) \\ge minsup$ then $X$ is a frequent itemset}$\n",
    "\n",
    "Example:\n",
    "\n",
    "$X = \\{\\text{Milk, Bread, Diapers}\\}$,\n",
    "$\\sigma(X) = 2$, $N = 5$, and $s(X) = 2/5 = 0.4$.\n",
    "\n",
    "If $minsup = 0.3$ then $X$ is a frequent itemset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3669cc8",
   "metadata": {},
   "source": [
    "## Finding Frequent Itemsets\n",
    "\n",
    "### Problem\n",
    "\n",
    "You need to find the frequent itemsets in market basket data.\n",
    "### Solution:\n",
    "Use mlxtend's `apriori` method:\n",
    "\n",
    "### Note: \n",
    "The `apriori` function expects data in a one-hot encoded pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0527b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Find frequent itemsets, input should be  a one-hot DataFrame\n",
    "\n",
    "min_support = 0.1 # set minsup \n",
    "\n",
    "frequent_itemsets = apriori(basket_df, min_support, use_colnames=True) #If use_colnames=True, uses DataFrames' column names \n",
    "                                                             # in the returned DataFrame instead of column indices.\n",
    "\n",
    "# Display results sorted by support value\n",
    "frequent_itemsets.sort_values(by=['support'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ee022",
   "metadata": {},
   "source": [
    "### Discussion \n",
    "\"Apriori is a popular algorithm [1] for extracting frequent itemsets with applications in association rule learning. The apriori algorithm has been designed to operate on databases containing transactions, such as purchases by customers of a store. An itemset is considered as \"frequent\" if it meets a user-specified support threshold. For instance, if the support threshold is set to 0.5 (50%), a frequent itemset is defined as a set of items that occur together in at least 50% of all transactions in the database... [From 2].\" \n",
    "\n",
    "### See Also\n",
    "* [1] [Fast algorithms for mining association rules](https://www.it.uu.se/edu/course/homepage/infoutv/ht08/vldb94_rj.pdf)\n",
    "* [2] [Frequent itemsets via apriori algorithm](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344fb5b",
   "metadata": {},
   "source": [
    "## Selecting and Filtering Frequent Itemsets\n",
    "### Problem\n",
    "You need to filter your frequent itemsets. \n",
    "\n",
    "### Solution\n",
    "Use mlxtend's `apriori`  method and then use pandas filtering techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ac0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Find frequent itemsets, input should be  a one-hot DataFrame\n",
    "\n",
    "min_support = 0.2 # set minsup \n",
    "\n",
    "frequent_itemsets = apriori(basket_df, min_support, use_colnames=True) #If use_colnames=True, uses DataFrames' column names \n",
    "                                                             # in the returned DataFrame instead of column indices.\n",
    "    \n",
    "# Add new column that stores the length of each itemset    \n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "frequent_itemsets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298fe113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the results that satisfy desired criteria:\n",
    "frequent_itemsets[ (frequent_itemsets['length'] == 2) &\n",
    "                   (frequent_itemsets['support'] >= 0.5) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f496d80",
   "metadata": {},
   "source": [
    "## 6. Association Rules\n",
    "* An *association rule* is an implication expression of the form $X \\implies Y,$ where $X$ and $Y$ are disjoint itemsets, i.e., $X \\cap Y = \\emptyset$.\n",
    "\n",
    "### Rule Evaluation Metrics (Support, Confidence)\n",
    "\n",
    "* The strength of an association rule can be measured in terms of its *support* and *confidence*. \n",
    "* An association rule's support determines how often a rule is applicable to a given dataset.\n",
    "\n",
    "$$\n",
    "\\text{Support, $s(X \\implies Y) = \\dfrac{\\sigma(X \\cup Y)}{|D|}$}.\n",
    "$$\n",
    "\n",
    "* An association rule's confidence determines how frequently items in $Y$ appear in transactions that contain $X$.\n",
    " \n",
    "$$\n",
    "\\text{Confidence, $c(X \\implies Y) = \\dfrac{\\sigma(X \\cup Y)}{\\sigma{(X)}}$}.\n",
    "$$\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider the rule $\\{\\text{Milk, Diapers}\\} \\implies \\{\\text{Beer}\\}$.  \n",
    "\n",
    "Because the support count for $\\{\\text{Milk, Diapers, Beer}\\}$ is 2 (see $t_3, t_4$) and the total number of transactions in the dataset is 5, the rule's support is $2/5 = 0.4$.\n",
    "\n",
    "The rule's confidence is obtained by dividing the support count for $\\{\\text{Milk, Diapers, Beer}\\}$ by the support count for $\\{\\text{Milk, Diapers}\\}$. Since there are 3 transactions that contain milk and diapers, the confidence for this rule is $2/3 = 0.67$. \n",
    "\n",
    "\n",
    "## Association Rule Mining Task\n",
    "\n",
    "* Given a set of transaction $D$, the goal of association rule mining is to find all the rules having support greater than $minsup$ and confidence greater than $minconf$ where $minsup$ and $minconf$ are the corresponding user-defined support and confidence thresholds.\n",
    "\n",
    "Examples:\n",
    "\n",
    "$ \\{\\text{Milk, Diapers}\\} \\implies  \\{ \\text{Beer} \\}$  $(s=0.4, c = 0.67)$,\n",
    "\n",
    "$ \\{\\text{Milk, Beer}\\} \\implies  \\{ \\text{Diapers} \\}$  $(s=0.4, c = 1.0)$,\n",
    "\n",
    "$ \\{\\text{Diapers, Beer}\\} \\implies  \\{ \\text{Milk} \\}$  $(s=0.4, c = 0.67)$,\n",
    "\n",
    "$ \\{\\text{Beer}\\} \\implies  \\{ \\text{Milk, Diapers} \\}$  $(s=0.4, c = 0.67)$,\n",
    "\n",
    "$ \\{\\text{Diapers}\\} \\implies  \\{ \\text{Milk, Beer} \\}$  $(s=0.4, c = 0.5)$,\n",
    "\n",
    "$ \\{\\text{Milk}\\} \\implies  \\{ \\text{Diapers, Beer} \\}$  $(s=0.4, c = 0.5)$,\n",
    "\n",
    "### Discussion:\n",
    "*  All the above rules are binary partitions of the same itemset:  $ X =  \\{\\text{Milk, Diapers, Beer} \\}$.\n",
    "\n",
    "* Rules originating from the same itemset have identical support but can have different confidence.\n",
    "\n",
    "* Thus, we may decouple the support and confidence requirements.\n",
    "\n",
    "This decoupling of support and confidence, the *Apriori* principle to prune frequent itemsets, and a similar rule pruning strategy are what enable efficient association analysis algorithms.  If a brute force method is used to compute the support and confidence for every possible rule, the total number of possible rules, $R$ extracted from a dataset that contains $d$ items is:\n",
    "\n",
    "$$\n",
    "R = 3^d - 2^{d+1} + 1.\n",
    "$$\n",
    "\n",
    "Even for a small dataset, like our prior example, where $d=5$, a brute force approach requires computation of support and confidence for $3^6 + 2^7 + 1 = 602$ rules.\n",
    "\n",
    "### *Apriori* Principle:\n",
    "If an itemset is frequent, then all of its subsets must also be frequent.  Conversely, if an itemset is infrequent, then all of its supersets are infrequent too.\n",
    "\n",
    "The later point is used for support-based pruning.\n",
    "\n",
    "\n",
    "<img src=\"https://cle.nps.edu/access/content/group/bb441168-9a75-4360-81fd-e8eb2ca7638e/Week%209%20_DL%20on%20Sakai_%3A%2021-25%20June/images/sbprune.png\" alt=\"An illustration of support-based pruninig\" style=\"height: 400px; width:400px;\"/>\n",
    "\n",
    "We can see in the figure that if $\\{a, b\\}$ is infrequent, then all supersets of $\\{a, b\\}$ are infrequent.\n",
    "\n",
    "### Rule Generation Strategy:\n",
    "\n",
    "**Theorem:**\n",
    "Let $Y$ be an itemset and $X$ is a subset of $Y$.  If a rule $X \\implies Y - X$ does not satisfy the confidence threshold, then any rule $\\bar{X} \\implies Y - \\bar{X} $, where $\\bar X$ is a subset of $X$, will NOT satisfy the confidence threshold either.\n",
    "\n",
    "\n",
    "<img src=\"https://cle.nps.edu/access/content/group/bb441168-9a75-4360-81fd-e8eb2ca7638e/Week%209%20_DL%20on%20Sakai_%3A%2021-25%20June/images/ruleprune.png\" alt=\"An illustration of pruning of association rules\" style=\"height: 400px; width:400px;\"/>\n",
    "From the figure above, suppose the confidence for $\\{bcd\\} \\implies \\{ a\\}$ is low.  All the rules containing item $a$ in its consequent, including $\\{cd\\} \\implies \\{ab\\}, \\{bd\\} \\implies \\{ac\\}, \\{cd\\} \\implies \\{ab\\}$ and $\\{d\\} \\implies \\{abc\\}$ can be discarded.\n",
    "\n",
    "## Mining Association Rules\n",
    "\n",
    "Mining association rules is a two-step process:\n",
    "1. **Frequent itemset generation**\n",
    "* Generate all itemsets whose support $\\gt minsup$.\n",
    "2. **Rule generation**\n",
    "* Generate high confidence rules ($ \\gt minconf$) from each frequent itemset, where each rule is a binary partitioning of a frequent itemset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ae8e1",
   "metadata": {},
   "source": [
    "## 7. Generate Association Rules from Frequent Itemsets\n",
    "### Problem\n",
    "Given a `DataFrame` of frequent itemsets, you want to generate association rules including the metrics `score`, `confidence`, and `lift`.\n",
    "\n",
    "### Solution\n",
    "\n",
    "Use mlxtend's `association_rules` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437cdb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de655fd",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "The `association_rules` method allows you to specify your\n",
    "1. metric of interest and,\n",
    "2. the according threshold. \n",
    "\n",
    "We can assert that we are interested in rules derived from the frequent itemsets only if the level of confidence is above the 70 percent threshold, thus we set `min_threshold=0.7`.\n",
    "\n",
    "\n",
    "### See Also\n",
    "[association_rules, mlxtend](http://rasbt.github.io/mlxtend/api_modules/mlxtend.frequent_patterns/association_rules/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3feee0f",
   "metadata": {},
   "source": [
    "## 8. Interestingness Measures\n",
    "\n",
    "* Association rule algorithms tend to produce too may rules.\n",
    "    \n",
    "    * Many are uninteresting or redundant.\n",
    "    * redundant if $\\{ A, B, C \\} \\implies \\{ D \\}$ and $\\{ A, B \\} \\implies \\{ D \\}$ have the same support and confidence.\n",
    "\n",
    "* Interestingness measures can be used to prune or rank the derived patterns.\n",
    "\n",
    "* In the original formulation of association analysis, support and confidence were the only measures.\n",
    "\n",
    "\n",
    "**Support:**\n",
    "\n",
    "Given a rule:\n",
    "\n",
    "$$\n",
    "A \\implies C,\n",
    "$$\n",
    "\n",
    "where $A$ is the antecedent and $C$ is the consequent, the *support* is calculated as \n",
    "\n",
    "$$\n",
    "s(A \\implies C) = s(A \\cup C), \\quad \\text{range: $[0, 1]$}.\n",
    "$$\n",
    "\n",
    "\n",
    "The `association_rules` method computes three different support metrics: \n",
    "1. Antecendent support, $s(A)$\n",
    "2. Consequent support, $s(C)$\n",
    "3. Support for the combined itemset $s(A \\cup C)$\n",
    "\n",
    "Support measures the abundance or frequency (often interpreted as significance or importance) of an itemset in a dataset.  Recall that we refer to a itemset as frequent if its support is greater than $minsup$. Additionally, due to the downward closure property, all subsets of a frequent itemset are also frequent.\n",
    "\n",
    "\n",
    "**Confidence**\n",
    "\n",
    "The *confidence* of a rule is the probability of seeing the consequent in a transaction given that it also contains the antecendent.  The metric is not symmetric or directed, since the confidence for $A \\implies C$ may be different than for $C \\implies A$.  The confidence is maximal, equal to 1, for a rule $A \\implies C$ if the consequent and antecedent always occur together.\n",
    "\n",
    "The confidence is calculated as \n",
    "\n",
    "$$\n",
    "c(A \\implies C) = \\dfrac{s(A \\cup C)}{s(A)}, \\quad \\text{range: $[0, 1]$}.\n",
    "$$\n",
    "\n",
    "**Lift**\n",
    "\n",
    "The *lift* metric is commonly used to measure how much more often the antecedent and consequent rule $A \\implies C$ occur together than would be expected if they were statistically independent.  If $A$ and $C$ are independent, the lift is exactly 1.\n",
    "\n",
    "The lift is calculated as \n",
    "\n",
    "$$\n",
    "\\text{lift}(A \\implies C) = \\dfrac{c(A \\implies C)}{s(C)}, \\quad \\text{range: $[0, \\infty]$}.\n",
    "$$\n",
    "\n",
    "\n",
    "**Leverage**\n",
    "\n",
    "The *leverage* metric measures the difference between the observed frequency of the antecedent and consequent appearing together and the frequency that would be expected if they were independent.  A leverage of 0 indicates independence.\n",
    "\n",
    "\n",
    "The leverage is calculated as \n",
    "\n",
    "$$\n",
    "\\text{leverage}(A \\implies C) = s(A \\implies C) - s(A) \\times s(C) , \\quad \\text{range: $[-1, 1]$}.\n",
    "$$\n",
    "\n",
    "**Conviction**\n",
    "\n",
    "The *conviction* is calculated as \n",
    "\n",
    "$$\n",
    "\\text{conviction}(A \\implies C) = \\dfrac{1 - s(C)}{1 - c(A \\implies C)},\\quad \\text{range: $[0, \\infty]$}.\n",
    "$$\n",
    "\n",
    "A high conviction means that the consequent is highly dependent on the antecedent.  For instance, in the case of a perfect confidence score (equal to 1), the denominator becomes 0 for which the conviction $\\rightarrow \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c55954",
   "metadata": {},
   "source": [
    "### See Also\n",
    "* [Selecting the right objective measure for association analysis](https://www.cse.msu.edu/~ptan/papers/IS.pdf)\n",
    "* [What makes patterns interesting in knowledge discovery systems](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.2780&rep=rep1&type=pdf)\n",
    "* \"Discovery, Analysis, and Presentation of Strong Rules\", G. Piatetsky-Shapiro (in Knowledge Discovery in Databases 1991), pp. 229-248. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c85f07",
   "metadata": {},
   "source": [
    "## 9. Rule Generation and Selection Criteria\n",
    "### Problem\n",
    "You want to evaluate rules based on different metrics of interest and different thresholds.\n",
    "\n",
    "### Solution\n",
    "Use mlxtend's `association_rules` method and adjust the `metric` and `min_threshold` parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611fabdd",
   "metadata": {},
   "source": [
    "We can see that only rules with a lift greater than 1.2 are displayed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b065f",
   "metadata": {},
   "source": [
    "## 10.  More Explicit Rule Mining\n",
    "### Problem\n",
    "We want to refine our rule selection criteria with different metrics and thresholds. \n",
    "### Solution\n",
    "Use pandas to set more explicit filtering criteria. For example, let's say that we are interested in the following criteria:\n",
    "1. at least two antecedents\n",
    "2. a confidence greater than 0.75\n",
    "3. a lift score greater than 1.2\n",
    "\n",
    "We could compute the antecedent length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[\"antecedent_len\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d3ad9",
   "metadata": {},
   "source": [
    "Then, we can use pandas' selection syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2537ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[ (rules['antecedent_len'] >= 2) &\n",
    "       (rules['confidence'] > 0.75) &\n",
    "       (rules['lift'] > 1.2) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f48cef",
   "metadata": {},
   "source": [
    "We can also select entries based on the \"antecedents\" or \"consequents\" columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[rules['antecedents'] == {'Diapers', 'Cola'}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
